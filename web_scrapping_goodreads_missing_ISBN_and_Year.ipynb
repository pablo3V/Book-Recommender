{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10006dda-2e1f-459b-9cd9-0f1c33b77a54",
   "metadata": {},
   "source": [
    "# Web Scraping in Goodreads\n",
    "\n",
    "This notebook is to get the **ISBN** of all these books that have this feature missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c4379-8e5e-47fe-9d6e-7146ef891199",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9086083c-def5-4f07-8578-fa893538eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests # Library used for making HTTP requests\n",
    "from bs4 import BeautifulSoup # Library for parsing HTML and XML documents\n",
    "from tqdm import tqdm # To include a progress bar in the loop\n",
    "import concurrent.futures # To make multiple http requests simultaneously\n",
    "import time # For time-related functions\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab905866-4221-4301-9290-1c7eb74aa8a6",
   "metadata": {},
   "source": [
    "### Useful Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31ca3b-38fa-4452-b8ab-9fa3a94dd464",
   "metadata": {},
   "source": [
    "Here we define a function that will be used in the loop to make an HTTP request to Goodreads. Then, the year of publication of the book with a given ISBN is searched for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b73cb48-c42d-468e-912a-d0c1bcea9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is in order for the request to work.\n",
    "# It seems that Goodreads blocks the requests made through a script.\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "\n",
    "def get_book_editions(book_workid):\n",
    "    url = f\"https://www.goodreads.com/work/editions/{book_workid}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        #print(f\"Error fetching the page: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    editions = soup.find_all('div', class_='editionData')\n",
    "\n",
    "    book_editions = []\n",
    "    for edition in editions:\n",
    "        edition_info = {}\n",
    "        title_tag = edition.find('a', class_='bookTitle')\n",
    "        if title_tag:\n",
    "            edition_info['title'] = title_tag.text.strip()\n",
    "            edition_info['link'] = \"https://www.goodreads.com\" + title_tag['href']\n",
    "    \n",
    "        if edition_info:\n",
    "            book_editions.append(edition_info)\n",
    "\n",
    "    return book_editions\n",
    "\n",
    "\n",
    "def get_missing_data(edition_url):\n",
    "    response = requests.get(edition_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        #print(f\"Error fetching the page: {response.status_code}\")\n",
    "        return None, None\n",
    "\n",
    "    #match = re.search(r'{\"__typename\":\"BookDetails\",\"[^}]*\"isbn\":\"[^\"]*\"', response.text)\n",
    "    match = re.search(r'{\"__typename\":\"BookDetails\",\"[^}]*\"language\":{\"__typename\":\"Language\",\"name\":\"[^\"]*\"}', response.text)\n",
    "    \n",
    "    if not match:\n",
    "        #print(\"No JSON data found\")\n",
    "        return None, None\n",
    "\n",
    "    json_data = match.group(0) + '}'  # We close the JSON with '\"}'\n",
    "\n",
    "    # Convert the JSON fragment into a dictionary\n",
    "    try:\n",
    "        book_details = json.loads(json_data)\n",
    "    except json.JSONDecodeError:\n",
    "        #print(\"Error decoding JSON\")\n",
    "        return None, None\n",
    "\n",
    "    isbn = book_details.get('isbn')\n",
    "    publication_time = book_details.get('publicationTime')\n",
    "    language = book_details.get('language').get('name')\n",
    "\n",
    "    # Convert publication time into a friendly format\n",
    "    if publication_time:\n",
    "        year = datetime.utcfromtimestamp(publication_time / 1000).strftime('%Y-%m-%d')[0:4]\n",
    "    else:\n",
    "        year = None\n",
    "\n",
    "    if language != 'English':\n",
    "        return None, None\n",
    "\n",
    "    #print(book_details)\n",
    "    return isbn, year \n",
    "\n",
    "\n",
    "def get_data(workid):\n",
    "    editions = get_book_editions(workid)\n",
    "    for edition in editions:\n",
    "        isbn, year = get_missing_data(edition['link'])\n",
    "        if isbn:\n",
    "            return isbn, year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6594f2-a3df-4851-a943-8ebc1a587375",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Here we load the books dataset from which we can get the ISBN of the books for which we want to find the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d4ca5d-e208-4e8d-a061-3e7f1824688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"archive/books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94df015-68ef-4b21-bac5-509a228b0042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   book_id                    10000 non-null  int64  \n",
      " 1   goodreads_book_id          10000 non-null  int64  \n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a7609d-dc85-4583-810d-a1c825221f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_books = books[books['isbn'].isnull() | books['original_publication_year'].isnull()].index\n",
    "books_missing_data = books.loc[missing_data_books].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2721a0-5414-49b5-a41e-07851e0dab61",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06985e-aa3a-48c0-a9d4-59b62a26ab06",
   "metadata": {},
   "source": [
    "What we do is divide the array of work_ids into a number of intervals determined by `divs`. This approach allows us to iterate over these intervals, and further within the work_ids inside each interval, specifying how many intervals we compile each time. This method gives us control over the web scraping, as simply iterating over the entire array of work_ids, i.e., `books['work_id']`, could potentially lead to various issues. Additionally, every time an interval is completed, we store the results in a CSV file to prevent any potential loss of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a88c776c-c067-410b-baa5-25aa86fddf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00%|██████████████████████████████████████| 359/359 [00:00<06:28,  1.08s/it]\n",
      "100.00%|██████████████████████████████████████| 359/359 [00:00<07:19,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "total = len(books_missing_data['work_id']) # total number of ISBNs\n",
    "divs = 2 # number of intervals in which we divide the isbns\n",
    "step = int(total / divs) # length of each interval\n",
    "ranges = [range(step*i - step, step*i) for i in range(1,divs+1)] # an array with the intervals\n",
    "\n",
    "key_i = 0 # number of the interval at which we start the for loop\n",
    "key_f = 2 # number of the interval at which we stop the for loop\n",
    "\n",
    "#progress_bar = tqdm(total=(key_f-key_i), bar_format='{percentage:.2f}%|{bar}| {n_fmt}/{total_fmt} [{remaining}<{elapsed}, {rate_fmt}]')\n",
    "\n",
    "for i in range(key_i, key_f): \n",
    "    \n",
    "    workids = books_missing_data['work_id'][ranges[i]] # ISBNs of the interval i\n",
    "    \n",
    "    progress_bar = tqdm(total=step, bar_format='{percentage:.2f}%|{bar}| {n_fmt}/{total_fmt} [{remaining}<{elapsed}, {rate_fmt}]')\n",
    "    \n",
    "    data_dict = {\n",
    "        'WorkID':[],\n",
    "        'ISBN':[],\n",
    "        'Year':[]\n",
    "    }\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor: \n",
    "        future_to_workid = {executor.submit(get_data, workid): workid for workid in workids}\n",
    "        for future in concurrent.futures.as_completed(future_to_workid):\n",
    "            workid = future_to_workid[future]\n",
    "            try:\n",
    "                isbn_workid, year_workid = future.result()\n",
    "                data_dict['WorkID'].append(workid)\n",
    "                data_dict['ISBN'].append(isbn_workid)\n",
    "                data_dict['Year'].append(year_workid)\n",
    "            except Exception as e:\n",
    "                data_dict['WorkID'].append(workid)\n",
    "                data_dict['ISBN'].append(np.nan)\n",
    "                data_dict['Year'].append(np.nan)\n",
    "            progress_bar.update(1)\n",
    "           \n",
    "    progress_bar.close()\n",
    "\n",
    "    new_df = pd.DataFrame(data_dict)\n",
    "\n",
    "    try:\n",
    "        existing_df = pd.read_csv(\"books_data_missing.txt\", sep=\"\\t\")\n",
    "    except FileNotFoundError:\n",
    "        existing_df = pd.DataFrame()\n",
    "\n",
    "    combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "    combined_df.to_csv(\"books_data_missing.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #progress_bar.update(1) \n",
    "    \n",
    "#progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934e8c5-1e0d-4ef7-9dce-79767d2b638b",
   "metadata": {},
   "source": [
    "1. ThreadPoolExecutor: concurrent.futures.ThreadPoolExecutor() creates a pool of threads that can be used to execute multiple calls to the process_isbn function simultaneously. Each thread in the pool will execute a specific task.\n",
    "\n",
    "2. executor.submit(): executor.submit(process_isbn, isbn) submits a task to the thread pool for execution. The submit function takes two arguments: the function to be executed (process_isbn) and the arguments to be passed to that function (isbn). It returns a Future object that represents the future result of the function call.\n",
    "\n",
    "3. {executor.submit(process_isbn, isbn): isbn for isbn in isbns}: This is a dictionary comprehension that creates a dictionary where the keys are Future objects returned by executor.submit() and the values are the corresponding ISBNs. This is used to keep track of which ISBN corresponds to which Future.\n",
    "\n",
    "4. concurrent.futures.as_completed(): This function takes an iterable of Future objects and returns an iterator that yields Future as they are completed. It waits until each Future is completed and then returns the completed Future. In this case, we are passing the future_to_isbn dictionary that contains all the Future objects we have created earlier.\n",
    "\n",
    "5. for future in concurrent.futures.as_completed(future_to_isbn):: We iterate over the iterator returned by as_completed(). As the Future objects are completed, the loop iterates over them in the order they are completed.\n",
    "\n",
    "6. isbn = future_to_isbn[future]: Since we are keeping track of which ISBN corresponds to which Future in our future_to_isbn dictionary, we can use the current Future to find its corresponding ISBN.\n",
    "\n",
    "7. future.result(): future.result() returns the result of the function call associated with the Future. If the function call has not yet finished, result() will block until it is completed. In this case, we are getting the result (i.e., the genre of the book) and storing it in the genres_isbn variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
